{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing data or training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df            = pd.read_csv ('preprocessed_data/g_df.csv')\n",
    "t_df            = pd.read_csv ('preprocessed_data/t_df.csv')\n",
    "G_T_df = pd.read_csv ('preprocessed_data/G_T_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82552, 3)\n",
      "(136, 464)\n",
      "(607, 55)\n"
     ]
    }
   ],
   "source": [
    "print (G_T_df.shape)\n",
    "print (g_df.shape)\n",
    "print (t_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Splitting for training, cross validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_T_train, G_T_test  = train_test_split (G_T_df, test_size = 0.1, random_state = rand_state  )\n",
    "G_T_train, G_T_cv    = train_test_split (G_T_train, test_size = 0.1, random_state = rand_state  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66866, 3)\n",
      "(7430, 3)\n",
      "(8256, 3)\n"
     ]
    }
   ],
   "source": [
    "print (G_T_train.shape)\n",
    "print (G_T_cv.shape)\n",
    "print (G_T_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Resampling training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0.0    64393\n",
       "1.0     2473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_T_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = G_T_train[G_T_train['target'] == 0]\n",
    "minority_class = G_T_train[G_T_train['target'] == 1]\n",
    "\n",
    "num_instances_to_replicate = len(majority_class) - len(minority_class)\n",
    "\n",
    "replicated_instances = resample(minority_class, n_samples=num_instances_to_replicate, random_state=42)\n",
    "\n",
    "# Concatenate the replicated instances with the original minority class\n",
    "balanced_G_T_train = pd.concat([majority_class, minority_class, replicated_instances])\n",
    "\n",
    "# shuffling train set\n",
    "balanced_G_T_train = balanced_G_T_train.sample(frac = 1, random_state= rand_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1.0    64393\n",
       "0.0    64393\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_G_T_train['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 128786 entries, 54731 to 69520\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   group ID      128786 non-null  object \n",
      " 1   technique ID  128786 non-null  object \n",
      " 2   target        128786 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "balanced_G_T_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Constructing Group, Technique, and Target matrices for Training, Cross Validation and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 464)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = pd.merge (g_df, balanced_G_T_train, on = 'group ID', how = 'right')\n",
    "G_train.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_train = pd.merge (t_df,balanced_G_T_train, on = 'technique ID', how = 'right')\n",
    "T_train.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n",
    "G_cv = pd.merge (g_df, G_T_cv, on = 'group ID', how = 'right') \n",
    "G_cv.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_cv = pd.merge (t_df, G_T_cv, on = 'technique ID', how = 'right')\n",
    "T_cv.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n",
    "G_test = pd.merge (g_df, G_T_test, on = 'group ID', how = 'right') \n",
    "G_test.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_test = pd.merge (t_df, G_T_test, on = 'technique ID', how = 'right')\n",
    "T_test.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128786, 464)\n",
      "(128786, 55)\n",
      "(128786, 3)\n",
      "(7430, 464)\n",
      "(7430, 55)\n",
      "(7430, 3)\n",
      "(8256, 464)\n",
      "(8256, 55)\n",
      "(8256, 3)\n"
     ]
    }
   ],
   "source": [
    "print (G_train.shape)\n",
    "print (T_train.shape)\n",
    "print (balanced_G_T_train.shape)\n",
    "\n",
    "print (G_cv.shape)\n",
    "print (T_cv.shape)\n",
    "print (G_T_cv.shape)\n",
    "\n",
    "print (G_test.shape)\n",
    "print (T_test.shape)\n",
    "print (G_T_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "\"G_train\" : G_train,\n",
    "\"T_train\" : T_train,\n",
    "\"balanced_G_T_train\" : balanced_G_T_train,\n",
    "\"G_cv\" : G_cv,\n",
    "\"T_cv\" : T_cv,\n",
    "\"G_T_cv\" : G_T_cv,\n",
    "\"G_test\" : G_test,\n",
    "\"T_test\" : T_test,\n",
    "\"G_T_test\" : G_T_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dfs.keys():\n",
    "    dfs[key].to_csv (f\"preprocessed_data/{key}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfNote01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
